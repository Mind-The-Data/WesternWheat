#!/usr/bin/env python2
# -*- coding: utf-8 -*-
"""
Created on Wed Sep 19 13:55:17 2018

@author: brian
"""

import matplotlib.pyplot as plt 
import numpy as np
import pandas as pd
import glob
import scipy.stats as st


def index_to_datetime(arg):
    date = pd.to_datetime(arg.split('_')[0])
    return date

crop_id = 23
crop_id = str(crop_id)
data_path = '../rawData/AgMet/'

print "Reading CDL dataframe from harddrive..."
dfCDL = pd.read_csv(data_path + "CDL" + crop_id + ".csv", usecols=['system:index','countyears','cropland_mode','first','system:indexviejuno'])
dfCDL['year'] = dfCDL['system:index'].apply(lambda x: x.split("_")[0]).astype(int)

dfCDL.rename(index=str, columns={'system:indexviejuno':'pixel'},inplace=True)

dfMaster = None
dfMaster = pd.DataFrame()
print "Loading EM spectral dataframes..."
for f in glob.glob(data_path + 'monthlyLSclass' + crop_id + '*'):
    dfMaster = pd.concat((dfMaster,  pd.read_csv(f)))

dfMaster.rename(index=str, columns={'system:indexviejuno':'pixel'},inplace=True)


print 'Performing Marcos date magic....'
# for 23 I had to add one to month as fractionofyear started at 2008.00 and ended at 2008.916 ... 
# Then make sure date calculation is correct. 
dfMaster['month'] = (((dfMaster['fractionofyear'] - dfMaster['fractionofyear'].astype(int))*12).round().astype(int)+1)
dfMaster['year'] = (np.modf(dfMaster['fractionofyear'])[1]).astype(int)
dfMaster['date'] = pd.to_datetime(dfMaster.year * 100 + (dfMaster.month), format='%Y%m')
dfMaster.index = dfMaster['date']
dfMaster = dfMaster.to_period('M')
# these two lines below not necessary... as dfMaster already has cropland_mode
lkupTable = dfCDL.pivot('year', 'pixel', 'first')
dfMaster['CDL'] = lkupTable.lookup(dfMaster['year'], dfMaster['pixel'])
print "Crop/fallow pixel filtering..."
dfMaster = dfMaster.loc[dfMaster['CDL'] == float(crop_id)]
####
# Investigating remote sensing data structure
#dfMaster.groupby(['pixel', 'month'])['B1'].count()
###
print "Calculating Vegetation Indices..."
dfMaster.index = dfMaster['pixel']
dfMaster.dropna(inplace=True)
dfMaster['NDVI'] = (dfMaster['B4'] - dfMaster['B3'])/(dfMaster['B4'] + dfMaster['B3'])
dfMaster['EVI'] = 2.5*(dfMaster['B4'] - dfMaster['B3'])/(dfMaster['B4'] + 6*dfMaster['B3']-7.5*dfMaster['B1']+1)
dfMaster['NDWI1'] = (dfMaster['B4'] - dfMaster['B5'])/(dfMaster['B4'] + dfMaster['B5'])
dfMaster['NDWI2'] = (dfMaster['B4'] - dfMaster['B7'])/(dfMaster['B4'] + dfMaster['B7'])



#tell me how many points we throw out
# initially I did below -1, however I had one point between 0 and -1 NDVI I want to throw out. 
NDVI_datapointsthrownout = dfMaster.loc[(dfMaster.NDVI<-1) | (dfMaster.NDVI>1)].count()
EVI_datapointsthrownout = dfMaster.loc[(dfMaster.EVI<-2) | (dfMaster.EVI>2)].count()
print "NDVI data points thrown out: " +str(NDVI_datapointsthrownout.NDVI)
print "EVI data points thrown out: " +str(EVI_datapointsthrownout.EVI)
#Investigating
#df = dfMaster.loc[(dfMaster.NDVI<-1) | (dfMaster.NDVI>1)]
pd.set_option('display.max_columns', 25)
neg =dfMaster.loc[(dfMaster.B3<0)]
#neg.info()
#df
#dfMaster.B3.sort_values().head(5)
#dfMaster.B4.sort_values().head(5)

#Throwing out points...
dfMaster=dfMaster.loc[(dfMaster.NDVI > -1.) & (dfMaster.NDVI <1.)]
dfMaster=dfMaster.loc[(dfMaster.EVI > -2.) & (dfMaster.EVI <2.)]


meanNDVI = dfMaster.groupby(['pixel', 'month'])['NDVI'].mean()
stdNDVI = dfMaster.groupby(['pixel', 'month'])['NDVI'].std()
#maxNDVI = dfMaster.groupby(['pixel', 'month', 'year'])['NDVI'].max()
#NDVI = dfMaster.groupby(['pixel', 'month' , 'year'])['NDVI'].mean()

meanEVI = dfMaster.groupby(['pixel', 'month'])['EVI'].mean()
stdEVI = dfMaster.groupby(['pixel', 'month'])['EVI'].std()
#maxEVI = dfMaster.groupby(['pixel', 'month', 'year'])['EVI'].max()
#EVI = dfMaster.groupby(['pixel', 'month','year'])['EVI'].mean()

meanNDWI1 = dfMaster.groupby(['pixel', 'month'])['NDWI1'].mean()
stdNDWI1 = dfMaster.groupby(['pixel', 'month'])['NDWI1'].std()
#NDWI1 = dfMaster.groupby(['pixel', 'month' ,'year'])['NDWI1'].mean()

meanNDWI2 = dfMaster.groupby(['pixel', 'month'])['NDWI2'].mean()
stdNDWI2 = dfMaster.groupby(['pixel', 'month'])['NDWI2'].std()
#NDWI2 = dfMaster.groupby(['pixel', 'month' ,'year'])['NDWI2'].mean()

print "Joining vegetation indices arrays into dfMaster..."
dfMaster = dfMaster.join(meanNDVI, on=['pixel', 'month'], rsuffix='mean')
dfMaster = dfMaster.join(stdNDVI, on=['pixel', 'month'], rsuffix='std')
#dfMaster = dfMaster.join(maxNDVI, on=['pixel', 'month' ,'year'], rsuffix='max')
#dfMaster = dfMaster.join(NDVI, on=['pixel', 'month', 'year'], rsuffix='monthly')

dfMaster = dfMaster.join(meanEVI, on=['pixel', 'month'], rsuffix='mean')
dfMaster = dfMaster.join(stdEVI, on=['pixel', 'month'], rsuffix='std')
#dfMaster = dfMaster.join(EVI, on=['pixel', 'month', 'year'], rsuffix='monthly')
#dfMaster = dfMaster.join(maxEVI, on=['pixel', 'month' ,'year'], rsuffix='max')

dfMaster = dfMaster.join(meanNDWI1, on=['pixel', 'month'], rsuffix='mean')
dfMaster = dfMaster.join(stdNDWI1, on=['pixel', 'month'], rsuffix='std')
#dfMaster = dfMaster.join(NDWI1, on=['pixel', 'month', 'year'], rsuffix='monthly')

dfMaster = dfMaster.join(meanNDWI2, on=['pixel', 'month'], rsuffix='mean')
dfMaster = dfMaster.join(stdNDWI2, on=['pixel', 'month'], rsuffix='std')
#dfMaster = dfMaster.join(NDWI2, on=['pixel', 'month', 'year'], rsuffix='monthly')

print 'Calculating Anomalies...'
dfMaster['zNDVI'] = (dfMaster['NDVI'] - dfMaster['NDVImean']) / dfMaster['NDVIstd']
dfMaster['zEVI'] = (dfMaster['EVI'] - dfMaster['EVImean']) / dfMaster['EVIstd']
dfMaster['zNDWI1'] = (dfMaster['NDWI1'] - dfMaster['NDWI1mean']) / dfMaster['NDWI1std']
dfMaster['zNDWI2'] = (dfMaster['NDWI2'] - dfMaster['NDWI2mean']) / dfMaster['NDWI2std']



#0.707107 comes up A LOT
#Mostly in winter months... Explaination:
# In months where there are very few data values (one or two), during the zscore operation, one value- one value equals some machine precision
# value, and it so happens these values produce a repeating .707107
### SOLVED!!!!!!!!!!
dfMaster.loc[np.isclose(dfMaster['zNDVI'].abs(), 0.707107), 'zNDVI'] = np.nan

## Investigating anomalies
### Lots of values near that abs 0.707107 value... can't just delete... right?
'''
dfMaster.zNDVI.sort_values().head()
dfMaster.zNDVI.sort_values().tail()
dfMaster.zNDVI.describe()
dfMaster.zNDVI.value_counts().sort_values()
dfMaster.zEVI.value_counts().sort_values()
dfMaster.zNDWI1.value_counts().sort_values()
dfMaster.zNDWI2.value_counts().sort_values()

df = dfMaster.loc[np.isclose(dfMaster['zNDVI'].abs(), .7071)]
df['pixel'].value_counts()
df.B5.value_counts()
df.NDVI.value_counts()
df.NDVI.value_counts().sort_values()
df.columns
df.NDVImean.value_counts()
df.NDVIstd.value_counts()
df.zNDVI.value_counts()
df.NDVI
df.Latitude.value_counts()
df.Longitude.value_counts()
df.month.value_counts()
#compared to dfmaster... how likely is this?
dfMaster.Longitude.value_counts()
dfMaster.Latitude.value_counts()
dfMaster.NDVI.value_counts()
dfMaster.NDVImean.value_counts()
dfMaster.NDVIstd.value_counts()

dfSpring = dfMaster.loc[(dfMaster['month'] > 1) & (dfMaster['month']< 5)]
dfSpring.Longitude.value_counts()
dfSpring.Latitude.value_counts()
dfSpring.NDVI.value_counts()
dfSpring.NDVImean.value_counts()
dfSpring.NDVIstd.value_counts()
dfSpring.zNDVI.value_counts()

dfspring = dfMaster.loc[np.isclose(dfMaster['zNDVI'].abs(), .7071) & (dfMaster['month'] > 1) & (dfMaster['month']< 5)]
dfspring.Longitude.value_counts()
dfspring.Latitude.value_counts()
dfspring.NDVI.value_counts()
dfspring.NDVImean.value_counts()
dfspring.NDVIstd.value_counts()
dfspring.zNDVI.value_counts()
'''
###### GEO split
dfMaster['.geo'] = dfMaster['.geo'].map(lambda x: str(x)[47:])    #deleting strings in column .geo
dfMaster['.geo'] = dfMaster['.geo'].map(lambda x: str(x)[:-2])
dfMaster['Longitude'], dfMaster['Latitude']= dfMaster['.geo'].str.split(',', 1).str
##################
#Investigating .geo split
##################
'''
lat = dfMaster['Latitude'].sort_values()
L = dfMaster['Longitude'].sort_values()
L.value_counts().sort_values()
l = dfMaster['longitude'].sort_values()
l.value_counts().sort_values()
plt.scatter( L, l)
l.count()
L.count()
'''
######################
######################
######################
# RollingWindowNDVI
######################
######################
######################

dfMaster.index = dfMaster.date # has to be a date index so when recombined it has date and pixel which makes unique

NDVIsum3=None
NDVIsum3 = dfMaster.groupby(['pixel','year']).rolling(3).NDVI.sum()
NDVIsum3 = NDVIsum3.reset_index(level=[0,1]) # from multi index to one index
NDVIsum3= NDVIsum3.reset_index(level=0) # change index to default range/period so date can be used by merge as a column
NDVIsum3.rename(index=str, columns={'NDVI':'NDVIsum3'}, inplace=True)
dfMaster = dfMaster.merge(NDVIsum3, on=['pixel', 'date'])
dfMaster.rename(index=str, columns={'year_x':'year'}, inplace=True)
dfMaster.drop(columns='year_y',inplace=True)

meanNDVIsum3 = dfMaster.groupby(['pixel', 'month'])['NDVIsum3'].mean()
stdNDVIsum3 = dfMaster.groupby(['pixel', 'month'])['NDVIsum3'].std()
dfMaster = dfMaster.join(meanNDVIsum3, on=['pixel', 'month'], rsuffix='mean')
dfMaster = dfMaster.join(stdNDVIsum3, on=['pixel', 'month'], rsuffix='std')
dfMaster['zNDVIsum3'] = (dfMaster['NDVIsum3'] - dfMaster['NDVIsum3mean']) / dfMaster['NDVIsum3std']

dfMaster.loc[np.isclose(dfMaster['zNDVIsum3'].abs(), 0.707107), 'zNDVIsum3'] = np.nan # Gotta figure this out...... 1/(2)**.5.




#dfMaster.index
#id_pixel = pd.unique(dfMaster.index)


#dfMaster.drop(columns=['','','','','','','','','',''])
print "Saving Vegetation Indices (" + crop_id + ") dataframe to hard drive..."
dfMaster[[u'fractionofyear',
       u'pixel', u'.geo', u'Latitude', u'Longitude', u'month', u'year', u'date',
       u'CDL',u'countyears',
       u'NDVI', u'EVI', u'NDWI1', u'NDWI2', u'NDVImean', u'NDVIstd', u'EVImean', u'EVIstd',
       u'NDWI1mean',u'NDWI2mean', u'NDWI1std', u'NDWI2std', u'zNDVI',
       u'zEVI', u'zNDWI1', u'zNDWI2','NDVIsum3',
       u'NDVIsum3mean', u'NDVIsum3std', u'zNDVIsum3']].to_csv(data_path + 'VegInd4_' + crop_id + '.csv')
#free memory
#dfMaster = None